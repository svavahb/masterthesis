\chapter{Discussion}
The results of the five test cases have been shown to support the claims of developers of the three communication methods GraphQL, RSocket and gRPC that services can benefit performance-wise from using them over RESTful HTTP APIs. 

In the standard case of submitting a single request for a single resource, the four methods all perform similarly. In the case where a single request is made for multiple connected resources, REST has a significantly worse performance. GraphQL and gRPC likely perform better than REST here due to their schema/protobuf which enables the avoidance of sending fields not needed for the use case at hand. RSocket does not offer this advantage, however its binary encoding is possibly contributing to its better performance than REST. As mentioned in the results section, this test case does show that using ad-hoc endpoints that do not fit with the RESTful architectural constraints can not achieve the same performance benefits as the other technologies, even though that is a common workaround for the problem of under-fetching.

However, in cases where other methods require multiple requests to fetch data where GraphQL can do it in one, GraphQL outperforms the others. In contrast, where all four technologies require the same number of requests, GraphQL does not outperform the others. This indicates that GraphQL's main advantage is in minimizing the amount of requests needed overall. For systems with complex underlying data models (especially ones based on graphs), this indicates that GraphQL is a very good choice. In a system with a simpler data model and simpler use cases (e.g. where a majority of use cases only depend on a single data resource), using GraphQL would not offer a major performance advantage.

In the cases where all four methods require multiple requests performed in sequence, RSocket and gRPC both benefit greatly from multiplexing by sending all requests over the same connection. Avoiding the overhead incurred by constantly needing to re-establish the connection thus offers a great advantage. For parallel requests however, this benefit could be counteracted by the overloading incurred by sending too many requests over the same connection. Further tests might need to be done to investigate at which point this trade-off switches, to provide guidelines to developers for when to spread the requests over multiple connections, and when using the same connection is sufficient. However, since gRPC does not allow for this in most implementations, in this aspect RSocket has the upper hand.

There are a few limitations with these experiments. Firstly, this thesis did not put any explicit focus on the performance of the data serialization (JSON vs Protocol Buffers). Some studies have been done on this topic, with PopiÄ‡ et al. showing that the size of messages can be minimized by 83\% by using protocol buffers rather than JSON \cite{popic2016performance}. In addition, Wibowo showed that the time taken to serialize messages went from around 10.5 \(\mu s\) with JSON to around 6.5 \(\mu s\) \cite{wibowo2011evaluation}. Given that gRPC was the only one out of the four that did not use Jackson for JSON serialization, it is possible that this gave gRPC an unfair advantage over the others. However, since most documentation and tutorials assume the usage of protocol buffers, the choice was made to use it as:
\begin{enumerate}
    \item There are few resources available that explain how to use other serialization methods.
    \item In practice, protocol buffers would most likely be used due to their status as the default serialization method.
\end{enumerate}
Thus, to emulate a real-world scenario, it was considered more prudent to use gRPC with protocol buffers. 

Next, the selection of the 0.5 second interval between requests in the experiments was not properly supported with arguments. Other theses with similar focus opted for either a 1 second interval \cite{johansson2017efficient} or a 0.5 second interval \cite{cederlund2016performance}. However, it would have been better to perform additional tests to see whether the 0.5 second interval was long enough to allow the services to cool down between requests. If any of the services require a longer time to cool down than the others, their performance would have been affected. This was not taken into consideration and could have changed the final conclusion. 

Finally, the author originally intended to also do experiments to see whether the four services behaved differently under load, which could provide insight into which of the four is best suited for larger systems with greater performance in high-traffic periods. However, due to time constraints this was not possible.