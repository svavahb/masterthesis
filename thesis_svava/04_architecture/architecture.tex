\chapter{Architecture comparison}\label{sec:comparison}
In this chapter, a comparative analysis of the four technologies will be conducted. First, the choice and usage of transfer protocols for each will be investigated, with a focus on improvements over HTTP/1.1. Then, the approaches each technology uses for interface design and contracting will be compared.

\section{Transfer protocols}\label{sec:transfer}
For microservices, communication is usually done via HTTP \cite{zimmermann2016microservices}, and before the release of HTT/2 in 2015, that was via HTTP/1.1. From 1999 until 2014, the HTTP/1.1 standard remained unchanged \cite{rfc2616}. One of the prominent issues with HTTP/1.1 is the fact that, for each transaction, a new connection must be established which increases overall latency when performing multiple requests \cite{spero1994analysis}. 

Since REST was designed with HTTP in mind, it is rarely used with anything else (although that is possible). That means that RESTful APIs usually suffer from this performance issue of HTTP/1.1. Furthermore, since a URI should only ever refer to a single resource within REST\cite{masse2011rest}, when a client needs to fetch multiple resources, multiple requests need to be issued and in turn, multiple connections need to be established.

GraphQL, while similarly platform independent yet rarely implemented over anything but HTTP/1.1, attempts to mitigate this issue by reducing the amount of requests needed to be made. By allowing clients to refer to any related resources in their queries, the overall request volume needed to fetch data can be decreased, improving performance \cite{schrock2015blog}. In the 2017 study on the performance differences between REST and GraphQL mentioned in chapter \ref{sec:related}, VÃ¡zquez-Ingelmo et al. found that the average response time of loading a specific dashboard decreased by 2 seconds, largely due to the fact that in REST, the action required 17 requests while with GraphQL, one was sufficient \cite{vazquez2017improving}.

gRPC however, is designed for and bound to HTTP/2. HTTP/2 is a new version of HTTP which adds multiplexing, allowing clients to send and receive more than one request/response message over the same connection \cite{rfc7540}. This allows gRPC clients to avoid the latency induced by having to re-establish a connection for each request, improving the overall performance. In addition, gRPC has no constraints or guidelines on the semantics of methods defined, meaning that if desired, developers can create methods that fetch all the data needed in a single request. Finally, HTTP/2 includes the feature of header compression, whereas in HTTP/1.1 headers are uncompressed and sent in plain text. This enables HTTP/2 payloads to be overall smaller, saving on bandwidth \cite{rfc7540}.

Finally, RSocket can bypass the issues of HTTP entirely. RSocket is a protocol defined at the same level as HTTP and works over binary, duplex protocols such as TCP. RSocket thus can also enjoy the benefit of multiplexing. Further, unlike all versions of HTTP currently in use, RSocket allows both the client and the server to act as sender and receiver. In a system that relies on e.g. push notifications, this can improve performance. With a HTTP-based implementation, the client would periodically need to poll the server to check for new notifications, potentially performing hundreds of requests without any meaningful response. With RSocket, the server can push data to the client only when there is data to push, reducing the overall amount of data sent between the two \cite{rsocketmotivations}. RSocket also reduces the bandwidth used by utilizing binary encoding, which makes the message less human-readable as opposed to a text-based encoding (like HTTP/1.1 uses) but is also more efficient \cite{ng2005study}.

\section{Interface design/contracting}
The interface contracting of REST lies mainly in the usage of HTTP verbs (\texttt{GET}, \texttt{POST}, \texttt{DELETE} etc.) as well as the choice of URI for each endpoint. As discussed in section \ref{sec:rest}, the same verb should consistently have the same semantics for each resource type. If a \texttt{GET} request is used to implement a method which fetches the entire representation of the resource identified by the URI, the same should go for any other resource. Throughout REST's lifetime, several guidelines and rulebooks have been created by other individuals than Fielding himself, detailing how the URIs should be constructed. However, none of these rules or guidelines are enforced by REST, since it is an architectural style rather than a protocol or framework. Developers are free to break the rules as they please, which they often do to circumvent issues caused by strict adherence to REST.

The two most common of these issues have been referred to as \textit{over-fetching} and \textit{under-fetching}. \textit{Over-fetching} results mainly from the aforementioned constraint for uniform HTTP method behavior. Since a \texttt{GET} request usually returns the resource's entire representation, that also means that in use cases where a client only really needs a subset of the fields, all of them will nevertheless be returned, using up bandwidth for data that is not needed. A common workaround for this is to define new representations of the same resource, tailored for each use case. This can quickly become confusing (especially when documentation is lacking) and cause a bloat in the codebase.
\textit{Under-fetching} is caused by the RESTful constraint that a URI should refer to a single resource. When a use case requires multiple resource types, this means that multiple requests need to be issued to the server, one for each resource type. In more complex use cases, this can cause a degradation in performance since each request adds network overhead with an increase in latency. This is often circumvented by developers defining custom, "ad-hoc" endpoints which return two or more resources at a time. These perform better, but do not conform with the REST style specification and should be avoided by anyone striving for a truly RESTful API.

GraphQL queries are pattern matching queries represented by a JSON\footnote{JavaScript Object Notation \cite{json}}-like tree structure with a specified type system defined by the server which is queried. The following query is a simple example of a GraphQL query, which locates a user with the ID \texttt{4} and returns their name, along with the names of the user's friends.
\begin{lstlisting}
type Query {
  getUser(id:4) {
    name
    friends {
      name
    }
  }
}
\end{lstlisting}
The type system of the GraphQL server is defined by a schema which specifies the fields belonging to each object type, and which values are allowed by each field (e.g. scalar or even other objects). This schema is also represented with a JSON-like structure.
Upon its release the query language offered two different operations, \textit{query} and \textit{mutation}. The query operation is a read-only pattern-matching fetch operation, while the mutation is a write operation followed by a fetch. A single GraphQL request is referred to as a \textit{document} and may contain multiple operations of any type as well as fragments, composition units allowing for query reuse.

The query functionality of GraphQL has several advantages over RESTful interfaces. The client-defined queries address both over- and under-fetching in one fell swoop by allowing clients both to specify exactly which fields they need, as well as utilizing the graph-like representation to allow clients to fetch not just one resource, but also any resource directly related to it. Furthermore, GraphQl offers benefits such as introspection (allowing clients to inspect the schema itself) and strong typing (enabling validation and guarantees about the shape of the data returned).

For gRPC, \textit{protobufs} are typically used to define a typed schema for service interfaces. Data structures are defined as messages in a \texttt{.proto} file, which is then used by a specialized compiler to generate code in the language preferred by the developer. This protobuf can then be shared with clients, to allow them to generate their own client-side stubs of the methods. Listing \ref{lst:proto} shows how an object might be defined in a protocol buffer file.
\begin{lstlisting}[caption={An example gRPC protocol buffer message definition}, captionpos=b,label={lst:proto}]
message User {
    string user_id = 1;
    string first_name = 2;
    repeated string phone_numbers = 3;
}
\end{lstlisting}
The \texttt{repeated} keyword indicates that the \texttt{phone\_numbers} field represents a collection (array, list etc) of strings. 
The integers assigned to each field represent the field's ID. If the server's \textit{proto} definition changes a field name, clients relying on older versions will still attempt to serialize based on the old specification. If the types do not match, a serialization error occurs. If a field is missing from the response, the client simply skips it in the serialization. This can cause issues if a message type changes often. Either the field is removed, running the risk of someone attempting to reuse the ID (which causes problems if the clients still include the old field) or the proto file slowly accumulates deprecated fields, causing bloat. 
The proto file is also used to define the services and methods available on the server:
\begin{lstlisting}[caption={An example gRPC protocol buffer service definition}, captionpos=b]
service UserService {
    rpc GetUser (UserRequest) returns (User) {}
    rpc getUsers (UsersRequest) returns (stream User) {}
}
\end{lstlisting}
Each method accepts one message type as parameter, and returns either a single message type, or a stream of one message type. Both the parameter and return type can only be a message, meaning that any primitive parameters need to be enclosed in a message type.
Similar to GraphQL, gRPC can avoid over-fetching through the usage of protobuf files. Unlike GraphQL however, this is not done through client-specified queries or methods. Any method and resource payload needs to be separately defined and tailored to each client's needs by the server itself. This can cause some bloat in the same way that multiple representations do for REST, but at least development time is minimized by the fact that the actual code needed to implement these representations is generated. Since gRPC does not set any rules for the semantics of methods, under-fetching can also be avoided by defining methods tailored to each use case, just as one would do in a non-distributed system.
gRPC has another disadvantage to GraphQL in regards to introspection. GraphQL's introspection allows clients to always be up-to-date on the construction of the schema, since the actual state of the schema at any point is returned immediately. In contrast, the protobuf files are statically shared with clients, causing the client copies to slowly drift out of sync with the schema as it is updated and changed. When relevant changes to the clients are published, a new version of the file needs to be manually sent to them. Developers can set up a system to make sure clients always have the newest version but this is not implemented by gRPC and depends on external systems or frameworks.

Finally, RSocket's only form of interface contracting is through the usage of \textit{mappings} to identify endpoints. There are no guidelines or rules for the semantics of these mappings and the developer is free to choose any string to represent and identify the methods. Methods can also be differentiated through their interaction models, which is usually implemented at the client-side with a specific method for each while at the server-side, the methods are identified via their accepted arguments and return types. A request-response method accepts a single argument and returns a single object while a fire-and-forget method accepts a single argument and has no return type (void). A request-response method accepts a single parameter but returns a stream of objects and finally, a channel method accepts a stream and returns a stream.

The lack of strict interface contracting and rules gives developers vast control over their API design. A method can easily be tailor-made to any use case required by clients, which would increase run-time performance and efficiency. With this control though, also comes a lack of restraint regarding the quality of the interface. An inexperienced developer could freely design an inefficient and confusing interface, and the lack of introspection or documentation about the interface could cause issues for clients and their developers. In addition, RSocket does not offer an efficient solution to the over-fetching problem. To prevent it, developers would have to resort to the same workaround as mentioned for REST (multiple representations of the same resource), with the same drawbacks. However, RSocket does offer more efficient encoding of the data than HTTP, minimizing the bandwidth used to transfer the same data.